import time
from langchain_qdrant import QdrantVectorStore
from qdrant_client import QdrantClient
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_ollama import ChatOllama
from langchain_classic.chains import create_retrieval_chain
from langchain_classic.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate

def start_agent():
    print("ğŸ§  Sistem BaÅŸlatÄ±lÄ±yor...")
    
    embedding_model = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2"
    )
    
    client = QdrantClient(path="./qdrant_db")
    
    vector_store = QdrantVectorStore(
        client=client,
        collection_name="my_documents",
        embedding=embedding_model,
    )
    
    retriever = vector_store.as_retriever(search_kwargs={"k": 3})
    
    # --- DEÄÄ°ÅÄ°KLÄ°K 1: Daha HÄ±zlÄ± Model ---
    print("ğŸš€ Ollama (Llama 3.2) BaÄŸlanÄ±yor...")
    llm = ChatOllama(
        model="llama3.2",  # 3 yerine 3.2 (Ã‡ok daha hÄ±zlÄ±)
        temperature=0.3,   # Biraz yaratÄ±cÄ±lÄ±k verelim ki cÃ¼mleler akÄ±cÄ± olsun
    )
    
    # --- DEÄÄ°ÅÄ°KLÄ°K 2: Kesin TÃ¼rkÃ§e Prompt ---
    prompt = ChatPromptTemplate.from_template("""
    Sen TÃ¼rkÃ§e konuÅŸan profesyonel bir yapay zeka asistanÄ±sÄ±n.
    AÅŸaÄŸÄ±daki "BaÄŸlam" (Context) bilgisini kullanarak kullanÄ±cÄ±nÄ±n sorusunu cevapla.
    
    Kurallar:
    1. CevabÄ± MUTLAKA TÃ¼rkÃ§e ver.
    2. EÄŸer cevap baÄŸlamda yoksa "DokÃ¼manlarda bu bilgiye ulaÅŸamadÄ±m" de.
    3. CevabÄ±n kÄ±sa, net ve anlaÅŸÄ±lÄ±r olsun.
    
    <BaÄŸlam>
    {context}
    </BaÄŸlam>

    Soru: {input}
    """)
    
    question_answer_chain = create_stuff_documents_chain(llm, prompt)
    rag_chain = create_retrieval_chain(retriever, question_answer_chain)
    
    print("\nâœ… NexusAI v2 HazÄ±r! (HÄ±zlandÄ±rÄ±lmÄ±ÅŸ Versiyon)\n")
    
    while True:
        user_input = input("Siz: ")
        if user_input.lower() == 'q':
            break
            
        start_time = time.time()
        print("âš¡ DÃ¼ÅŸÃ¼nÃ¼yor...", end="\r")
        
        try:
            response = rag_chain.invoke({"input": user_input})
            end_time = time.time()
            duration = end_time - start_time
            
            print(f"\nNexusAI ({duration:.2f}sn):")
            print(response["answer"])
            
            print("\n--- Kaynaklar ---")
            for i, doc in enumerate(response["context"]):
                # Ä°Ã§eriÄŸi temizleyip (boÅŸluklarÄ± silip) ilk 50 karakteri gÃ¶sterelim
                content_preview = doc.page_content.replace("\n", " ")[:50]
                print(f"[{i+1}] ...{content_preview}...")
            print("-" * 50)
            
        except Exception as e:
            print(f"\nâŒ Bir hata oluÅŸtu: {e}")

if __name__ == "__main__":
    start_agent()